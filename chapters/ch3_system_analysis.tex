\chapter{System Analysis}

\section{Functional Requirements}

\subsection{Firmware Image Processing (FR-1)}

The system shall extract, analyze, and prepare firmware images for emulation. Input includes firmware binary files in common formats (.bin,.img,.zip,.tar.gz). Processing extracts filesystem contents using binwalk and complementary tools, identifies embedded Linux kernel version and architecture, locates configuration files and executables, analyzes filesystem structure determining device type and manufacturer, and generates metadata describing firmware characteristics. Output includes extracted filesystem directory preserving original hierarchy, metadata JSON file containing kernel version and architecture details, and analysis report summarizing firmware contents. This high-priority requirement provides foundational capability required for firmware emulation. Validation confirms successful extraction from firmware images representing major device categories and processor architectures.

\subsection{Automated Firmware Emulation (FR-2)}

The system shall emulate extracted firmware in QEMU-based virtual environments using advanced arbitration techniques. Input includes extracted firmware filesystem, identified kernel image, device-specific configuration parameters, and emulation preferences. Processing configures QEMU virtual machines with appropriate architecture and resources, selects matching kernel images, applies boot process arbitration for non-standard initialization, configures network interfaces using arbitration techniques, implements NVRAM emulation for persistent storage, monitors emulation health, and applies systematic interventions when failures occur. Output includes running emulated firmware instance accessible via network, console logs documenting boot process, NVRAM contents showing configuration, and status reports with diagnostic information. This high-priority core capability enables dynamic firmware analysis. Validation achieves emulation success exceeding 75\% across diverse collections with network accessibility verification.

\subsection{Vulnerability Analysis Testing (FR-3)}

The system shall perform automated vulnerability testing against emulated firmware instances. Input includes running emulated instances, applicable CVE lists, fuzzing templates, and exploitation modules. Processing enumerates exposed services, queries vulnerability databases for known CVEs affecting identified versions, executes exploit modules attempting vulnerability triggers, performs fuzzing of web interfaces and services, monitors for crashes and authentication bypasses, and documents successful exploits with proof-of-concept. Output includes comprehensive vulnerability assessment reports with CVE identifiers and severity ratings, successful exploit demonstrations with evidence, remediation recommendations, and crash dumps when exploitation causes failures. High priority demonstrates practical security impact of identified vulnerabilities.

\subsection{Network Device Discovery (FR-4)}

The system shall identify active devices within specified network ranges using ARP and TCP scanning. Input includes IP address ranges in CIDR notation, optional port range specifications, and scan intensity parameters. Processing validates CIDR notation determining target ranges, generates IP address lists, sends ARP requests across subnets, collects responses containing IP/MAC pairs, performs TCP SYN scans on commonly used ports, attempts full connections for banner grabbing, correlates ARP and TCP results by IP address, and handles network errors gracefully. Output includes device inventory listing IP addresses, MAC addresses, response timestamps, open TCP ports per device, service banners identifying software versions, and reachability metrics. High priority provides essential network visibility. Validation confirms accurate discovery of all test network devices with Class C subnet completion within 5 minutes.

\subsection{Device Identification (FR-5)}

The system shall identify device vendors and types based on MAC addresses and service fingerprints. Input includes MAC addresses from scans, open port lists, service banners, and optional additional context. Processing extracts OUI from MAC addresses, queries local OUI databases determining manufacturers, analyzes open port patterns against device signatures, parses service banners for vendor strings and versions, applies heuristic rules combining multiple indicators, and assigns confidence scores to classifications. Output includes enhanced inventory with manufacturer names, device types with confidence scores, firmware versions from banners, and model numbers when identifiable. Medium priority enhances inventory quality beyond basic scanning.

\subsection{Traffic Capture and Preprocessing (FR-6)}

The system shall capture network traffic and preprocess into formats suitable for deep learning models. Input includes network interface specifications, capture duration parameters, and BPF filters for selective capture. Processing initializes packet capture using libpcap, captures matching packets, extracts relevant features including packet sizes and protocol distributions, aggregates packet-level features into flow-level statistics, normalizes feature values, encodes categorical variables numerically, and handles missing data. Output includes preprocessed feature matrices in NumPy format with rows as samples and columns as features, metadata describing feature definitions and scaling parameters, and optionally raw PCAP files for reference. High priority essential for malware detection capability.

\subsection{Malware Classification (FR-7)}

The system shall classify network traffic as malicious or benign using trained CNN models. Input includes preprocessed feature matrices from traffic capture. Processing loads pre-trained model weights, validates input dimensions match expectations, performs forward propagation through convolutional and dense layers, applies batch normalization, generates output activations, applies softmax producing probability distributions, selects highest probability classes as predictions, and applies confidence thresholds rejecting low-confidence predictions. Output includes classification results indicating benign or malicious, specific malware families when malicious, confidence scores, and optionally detailed feature importance analysis. High-priority core malware detection capability. Validation achieves classification accuracy exceeding 95\% on test sets with both precision and recall above 90\% per malware family.

\subsection{Model Training (FR-8)}

The system shall support training and fine-tuning of deep learning models on custom datasets. Input includes labeled datasets with ground truth classifications, training hyperparameters, and optional pre-trained weights for transfer learning. Processing loads and validates datasets ensuring sufficient samples per class, splits into training/validation/test sets ensuring balance, applies data augmentation if beneficial, initializes or loads model weights, implements training loops with batch gradient descent calculating losses and gradients, applies optimization algorithms updating weights, implements dropout regularization during training, normalizes activations with batch normalization, monitors metrics after each epoch, implements early stopping preventing overfitting, and selects best weights based on validation performance. Output includes trained model weights, training history plots, comprehensive performance metrics, and feature importance analysis. Medium priority enables customization beyond pre-trained models.

\subsection{Integrated Dashboard (FR-9)}

The system shall provide unified web-based interface displaying results from all modules. Input includes user authentication credentials, query parameters for filtering, and visualization preferences. Processing authenticates users verifying authorization, queries databases for firmware/network/malware results, aggregates data correlating by device identifiers, generates visualizations including topology graphs and vulnerability heat maps, formats reports in HTML/PDF/JSON formats, and applies access controls ensuring users see only authorized data. Output includes interactive web dashboard with real-time updates, drill-down capabilities, filtering and search functionality, and downloadable reports. Medium priority enhances usability though system can operate via command-line interfaces.

\subsection{Alert Generation (FR-10)}

The system shall generate alerts when critical vulnerabilities or malware infections are detected. Input includes configured alert thresholds and severity levels, notification preferences, and suppression rules preventing flooding. Processing monitors analysis results real-time for high-severity findings including critical vulnerabilities with CVSS $\geq$ 7.0, malware detections with confidence $\geq$ 90\%, unusual network patterns, and firmware with known backdoors, evaluates findings against configured rules, applies suppression avoiding duplicates, formats alert messages with relevant details including affected device identification and remediation recommendations, and delivers via configured channels. Output includes timely notifications via email with formatted messages, HTTP POST requests to webhooks with JSON payloads, dashboard popup notifications, and optionally SMS for critical alerts. Medium priority improves response time.

\section{Non-Functional Requirements}

\subsection{Performance and Scalability (NFR-1)}

The system shall support parallel processing maintaining acceptable performance as workload increases. For firmware emulation, process 50+ images per hour using 8-core processors, support concurrent emulation of 10+ instances, and scale linearly adding processing nodes. For network scanning, complete Class C subnet scans within 5 minutes, support Class B subnets within 2 hours, and handle concurrent scan requests without interference. For malware classification, process 100+ samples per minute on CPU, process 1000+ samples per minute with GPU acceleration, and maintain inference latency below 100ms per sample on GPU. Security assessments of large IoT deployments require processing many firmware images and scanning extensive networks, making performance and scalability essential.

\subsection{Reliability and Fault Tolerance (NFR-2)}

The system shall handle errors gracefully maintaining availability and data integrity when components experience issues. Implementation includes comprehensive exception handling for all external interactions, detailed error logging with stack traces and system state, automatic retry with exponential backoff for transient failures, isolation of firmware emulation failures preventing system-wide impacts through containerization, health checks for all services with automatic restart of failed components, and database consistency through transactions and proper rollback. Measurement targets system uptime $>$ 99\% during continuous operation excluding planned maintenance, error recovery success rate $>$ 95\% for transient failures, no data loss or corruption when components fail, and mean time to recovery $<$ 5 minutes for component failures.

\subsection{Usability and Accessibility (NFR-3)}

The system shall provide intuitive interfaces accessible to users with varying technical expertise from security experts to network administrators. Specifications include web dashboard requiring no specialized training for basic operations, clear informative error messages with suggested remediation, command-line interfaces supporting comprehensive help documentation, interactive tutorials guiding new users through common workflows, consistent terminology and interface conventions, and responsive design supporting desktop and tablet form factors. Measurement targets new users completing basic scanning workflows within 15 minutes of first use, user satisfaction ratings $>$ 4.0/5.0 in surveys, error messages enabling users to resolve common issues without support, and dashboard navigation intuitive to 90\%+ of users on first attempt.

\subsection{Security and Privacy (NFR-4)}

The system shall protect sensitive security data preventing unauthorized access ensuring the security tool itself doesn't introduce vulnerabilities. Implementation includes role-based access control with Admin/Analyst/Viewer roles, AES-256 encryption for sensitive data at rest including passwords and vulnerability details, TLS 1.3 for all network communications, secure session management with secure httpOnly cookies and JWT tokens with appropriate expiration, audit logging of all administrative actions, OWASP Top 10 guideline adherence, input validation and sanitization preventing injection attacks, and principle of least privilege throughout design. A compromised security tool provides attackers valuable reconnaissance data. Validation includes automated vulnerability scanning, manual penetration testing, and code review focusing on security with no high or critical vulnerabilities.

\subsection{Maintainability and Extensibility (NFR-5)}

The system architecture shall facilitate maintenance, updates, and feature additions enabling long-term evolution without major rewrites. Specifications include modular architecture with well-defined interfaces via RESTful APIs and message queues, comprehensive code documentation following industry standards with docstrings and inline comments for complex logic, unit test coverage $>$ 80\% for critical modules, integration tests covering major end-to-end workflows, configuration externalized to files separate from code in JSON/YAML/environment variables, version control with git using feature branches and pull requests, and continuous integration pipelines running tests on every commit. Measurement targets code maintainability index $>$ 70, average time for minor feature additions $<$ 1 week, and regression bug rate $<$ 2\% per release.

\subsection{Portability and Deployment (NFR-6)}

The system shall support deployment across diverse computing environments from developer workstations to cloud platforms. Specifications include Docker containerization for consistent deployment regardless of host environment, support for major Linux distributions including Ubuntu 20.04+, Debian 11/12, CentOS 8+, and Rocky Linux 8+, cloud-compatible architecture supporting AWS, Azure, and Google Cloud Platform, automated deployment scripts and comprehensive installation documentation, clearly documented resource requirements with minimum and recommended specifications, and support for x86\_64 and ARM64 architectures where practical. Measurement targets successful deployment on all specified distributions and cloud platforms, installation time $<$ 30 minutes following documentation, and zero manual configuration for basic deployment with sensible defaults.

\subsection{Documentation and Training (NFR-7)}

The system shall include comprehensive documentation supporting installation, configuration, operation, and troubleshooting. User documentation includes installation guides with step-by-step instructions for different environments, user manuals covering all features with screenshots and examples, configuration references documenting all parameters, troubleshooting guides for common issues with solutions, and FAQs addressing frequent questions. Developer documentation includes architecture documentation with diagrams explaining system design, API references with endpoint descriptions and examples, extension guides showing how to add new modules, code documentation via docstrings for all public interfaces, and contribution guidelines for external developers. Training materials include tutorial videos demonstrating key workflows, sample datasets for experimentation, case studies showing real-world applications, and presentation slides for classroom training. Measurement targets documentation completeness covering all features, documentation accuracy with tested procedures working as described, and user ability to complete tasks using documentation only with $>$90\% success rate.

\section{Feasibility Analysis}

\subsection{Technical Feasibility}

Published research demonstrates technical feasibility of automated firmware emulation with arbitrated approaches achieving 79.36\% success across diverse collections. The framework's implementation details are openly published enabling replication. Our team possesses necessary technical skills including Linux system internals knowledge, virtualization experience with QEMU/KVM, Python proficiency for automation, and networking understanding. Required technologies are mature and stable: QEMU provides robust full-system emulation, binwalk reliably extracts filesystems, standard Linux utilities handle filesystem manipulation, and Docker enables containerized deployment. Assessment: Technically Feasible---proven technology with clear implementation path.

Network scanning using ARP and TCP techniques is well-established with numerous successful implementations. Python libraries provide necessary functionality through Scapy for packet manipulation, socket for TCP connections, concurrent.futures for multi-threading, and established MAC vendor databases. Our team has networking experience including OSI model understanding, network programming experience, and security tools familiarity. The technologies are mature with ARP standard since 1982 and TCP since 1981. Assessment: Technically Feasible---straightforward implementation using proven techniques.

Deep learning frameworks provide robust foundations for CNN-based malware classifiers. TensorFlow/Keras offer high-level APIs simplifying model development, GPU acceleration through CUDA/cuDNN, and extensive documentation with community support. Published research demonstrates accuracy exceeding 95\% on labeled datasets validating approaches. Our team has machine learning knowledge including neural networks understanding, Python experience with NumPy/Pandas, and model training familiarity. Required datasets are available through IoT-23 from Stratosphere Laboratory and other public malware datasets. Assessment: Technically Feasible---proven deep learning approaches with accessible frameworks.

Modern software engineering practices enable integration of independent modules. RESTful APIs provide standardized inter-module communication, message queues enable asynchronous processing, shared databases facilitate data exchange, and Docker containerization simplifies deployment. Our team has software engineering experience including API design, database schema design, web application development, and system integration experience. Integration patterns are well-established with microservices as industry standard. Assessment: Technically Feasible---standard integration patterns with proven technologies. Overall Technical Feasibility Conclusion: All major components have proven implementations, integration patterns are well-understood, required technologies are mature and stable, our team has necessary skills, and no fundamental technical barriers exist. Verdict: TECHNICALLY FEASIBLE.

\subsection{Operational Feasibility}

Target users including security researchers, network administrators, and security analysts possess sufficient technical background to operate command-line and web interfaces effectively. They are already familiar with security tools and concepts. Web-based interfaces reduce learning curves compared to command-line-only tools while comprehensive documentation and tutorials support onboarding. Our value proposition addresses genuine user needs including lack of comprehensive IoT security tools, frustration with fragmented existing solutions, and demand for automated security assessment capabilities. Early feedback from potential users indicates strong interest.

Docker containerization dramatically simplifies installation, updates, and troubleshooting compared to traditional deployment. Standard Linux system administration skills suffice for deployment and maintenance. Infrastructure requirements including servers and databases are familiar to IT departments. Cloud deployment options eliminate on-premises infrastructure requirements for organizations preferring cloud solutions. Most organizations already have Linux servers or cloud accounts, PostgreSQL/MongoDB familiarity as common databases, and Docker experience increasingly standard.

RESTful APIs enable integration with existing SIEM platforms, ticketing systems like Jira and ServiceNow, and security orchestration tools. Standard data formats including JSON and CSV facilitate data exchange. Webhook notifications push alerts to external systems. Organizations can incorporate our system into existing security operations workflows without major disruption. Common integration scenarios include exporting findings to SIEM for correlation, creating tickets automatically when high-severity findings are detected, and triggering automated response playbooks via SOAR platforms.

Comprehensive documentation reduces training requirements. Web-based interfaces are intuitive for users with basic technical literacy. Command-line interfaces follow common conventions familiar to Linux users. Tutorial videos and examples provide self-service training resources while community forums enable peer support. Expected training timeline includes 1--2 hours for basic operation, 1--2 days for advanced features and customization, and ongoing learning through experimentation. Overall Operational Feasibility Conclusion: System design aligns with user capabilities and expectations, deployment and maintenance require only standard widely available skills, integration capabilities support incorporation into existing workflows, and training requirements are reasonable given target user background. Verdict: OPERATIONALLY FEASIBLE.

\subsection{Economic Feasibility}

For academic context, software development cost is \rupee 0 as student labor is not salaried. Development hardware costs \rupee 120,000-\rupee 180,000 for workstation with suitable specifications. Cloud infrastructure for development/testing is \rupee 0-\rupee 10,000/month optional for testing scenarios using free tiers initially. Personnel costs are \rupee 0 in academic context. Total development cost in academic context is \rupee 120,000-\rupee 180,000 for hardware only.

Deployment costs vary by scenario. On-premises deployment requires hardware costing \rupee 150,000-\rupee 400,000 for servers, \rupee 10,000-\rupee 50,000 for network equipment, and \rupee 20,000-\rupee 50,000 for UPS and peripherals, totaling \rupee 180,000-\rupee 500,000 one-time with \rupee 20,000-\rupee 50,000 annual maintenance. Cloud deployment costs \rupee 20,000-\rupee 200,000/month depending on scale with \rupee 0 software costs as open-source software runs on cloud infrastructure. Hybrid deployment combines on-premises for sensitive data and cloud for scalability costing \rupee 100,000-\rupee 300,000 initial plus \rupee 30,000-\rupee 80,000/month ongoing.

Return on investment through cost avoidance includes preventing security breaches averaging \rupee 50 lakhs-\rupee 1 crore for SMBs with even preventing one small breach justifying system cost. Saved analysis time worth \rupee 50,000-\rupee 100,000/month in analyst salaries translates to \rupee 200,000-\rupee 400,000/year in analyst time savings through manual firmware analysis automation saving 40--80 hours/month and network scanning saving 20--40 hours/month. Automated vulnerability discovery provides 10--100x cheaper pre-deployment identification versus post-deployment patching with product recalls for security issues costing \rupee 10 lakhs-\rupee 1 crore+ prevented through early discovery.

Conservative ROI calculation with \rupee 180,000 on-premises initial cost plus \rupee 50,000 annual maintenance versus \rupee 15 lakhs annual benefit from 30\% breach probability avoidance (0.3 $\times$ \rupee 50 lakhs = \rupee 15 lakhs) plus \rupee 3 lakhs saved analyst time totals \rupee 18 lakhs annual benefit. Year 1 ROI is (\rupee 18 lakhs - \rupee 50,000 - \rupee 1.8 lakhs) / \rupee 2.3 lakhs $\times$ 100 = 680\%. Year 2+ ROI is (\rupee 18 lakhs - \rupee 50,000) / \rupee 50,000 $\times$ 100 = 3500\%.

Comparison to commercial alternatives costing \rupee 5--20 lakhs/year in licenses, \rupee 2--10 lakhs implementation, and 15--20\% annual support shows our system 3-year cost of \rupee 3.3 lakhs on-premises or \rupee 18 lakhs cloud (medium) versus commercial 3-year cost of \rupee 20 lakhs-\rupee 80 lakhs+, providing cost savings of \rupee 16.7 lakhs-\rupee 76.7 lakhs over 3 years. Overall Economic Feasibility Conclusion: Open-source foundation minimizes software costs, hardware costs are modest and typical for enterprise IT, development costs are primarily hardware in academic context, deployment costs vary but are manageable, ROI is strongly positive even with conservative estimates, and cost savings versus commercial alternatives are substantial. Verdict: ECONOMICALLY FEASIBLE.

\section{Hardware Requirements}

\subsection{Development Environment Specifications}

Minimum specifications include Intel Core i5--8400 or AMD Ryzen 5 2600 with 6 cores at 2.8 GHz base clock, 16 GB DDR4 RAM minimum for comfortable development with multiple VMs and containers, 256 GB SSD for operating system and development tools plus 1 TB HDD for firmware image storage and datasets, integrated graphics sufficient though dedicated GPU recommended for deep learning, Gigabit Ethernet adapter at 1000 Mbps, and Ubuntu 20.04 LTS or later. These minimum specifications enable basic development activities including running development tools and IDEs, testing firmware emulation of single instances, training small-scale machine learning models, and running unit and integration tests, though parallel processing and large-scale testing will be limited.

Recommended specifications include Intel Core i7--11700K or AMD Ryzen 7 5800X with 8 cores at 3.6 GHz base and 4.9 GHz boost, 32 GB DDR4 RAM at 3200 MHz or faster, 512 GB NVMe SSD PCIe 3.0 or 4.0 for OS and development tools plus 2 TB HDD 7200 RPM for firmware images and datasets plus optional 500 GB external SSD for backups, NVIDIA GeForce RTX 3060 with 12 GB VRAM or better for GPU-accelerated deep learning, dual Gigabit Ethernet adapters for management and scanning isolated test networks, 27-inch 1440p monitor for improved productivity, mechanical keyboard and precision mouse, UPS for power protection, and Ubuntu 22.04 LTS. Recommended specifications enable efficient development with concurrent emulation of multiple firmware instances, rapid deep learning model training with GPU acceleration, smooth operation of resource-intensive IDEs, parallel testing workflows, and comfortable multitasking.

\subsection{Production Deployment Hardware}

Small-scale deployment suitable for organizations with 1--100 devices requires Intel Xeon E-2236 with 6 cores at 3.4 GHz or AMD EPYC 7232P with 8 cores at 3.2 GHz, 32 GB ECC RAM, 512 GB NVMe SSD plus 2 TB HDD or SSD, dual 10 Gigabit Ethernet adapters, optional 550W redundant power supply, 1U or 2U rackmount server or tower workstation form factor, estimated cost \rupee 150,000-\rupee 250,000, and capacity to analyze 50--100 firmware images, scan networks up to 500 devices, and process 1000--5000 malware samples per day.

Medium-scale deployment suitable for organizations with 100--1000 devices requires dual Intel Xeon Silver 4314 with 32 cores total at 2.4 GHz or AMD EPYC 7452 with 32 cores at 2.35 GHz, 128 GB ECC RAM with 8$\times$16GB modules for dual-channel, 1 TB NVMe SSD plus 8 TB RAID 10 array plus optional SAN or NAS for extended storage, optional but recommended NVIDIA Tesla T4 or A40 for high-throughput malware classification, dual 25 Gigabit Ethernet adapters with failover, dual redundant 750W power supplies, 2U rackmount server form factor, estimated cost \rupee 400,000-\rupee 700,000, and capacity to analyze 500--1000 firmware images per day, scan networks with thousands of devices, and process 50,000+ malware samples per day with GPU.

Large-scale deployment suitable for enterprises with 1000+ devices uses distributed cluster architecture. Master node requires dual Intel Xeon Gold 6230 with 40 cores total, 256 GB ECC RAM, 2 TB NVMe SSD, and dual 100 Gigabit Ethernet. Worker nodes (3--10 nodes) require dual Intel Xeon Silver or AMD EPYC processors, 128 GB ECC RAM per node, 1 TB NVMe SSD per node, and 25--100 Gigabit Ethernet. GPU nodes (1--3 nodes for ML inference) require Intel Xeon or AMD EPYC processors, 256 GB RAM, 4$\times$ NVIDIA A100 (40GB or 80GB) per node, 2 TB NVMe SSD, and 100 Gigabit InfiniBand or Ethernet. Enterprise SAN or distributed storage provides 50+ TB capacity. Estimated cost is \rupee 2,500,000-\rupee 8,000,000 with capacity to analyze thousands of firmware images daily, scan enterprise networks with tens of thousands of devices, process millions of malware samples per day, and support multiple concurrent security analysts.

\section{Software Requirements}

\subsection{Core System Software}

Primary operating system is Ubuntu 22.04 LTS providing 5 years of security updates, extensive package repositories, strong community support, excellent Docker compatibility, and widespread industry adoption. Alternatives include Ubuntu 20.04 LTS, Debian 11/12, Rocky Linux 8/9, and CentOS Stream 8/9. Python environment requires Python 3.8, 3.9, 3.10, or 3.11 with pip 21.0+ for package installation, virtualenv or conda for environment isolation, and setuptools and wheel for package building. Containerization uses Docker CE 20.10+ and Docker Compose 1.29+ for multi-container orchestration with optional Kubernetes 1.24+ and Helm 3.x for large-scale distributed deployment.

\subsection{Firmware Emulation Software}

QEMU 5.0+ provides full system emulation with qemu-system-mips, qemu-system-arm, qemu-system-x86, and qemu-system-ppc packages supporting MIPS, ARM, x86, and PowerPC architectures. Firmware extraction tools include binwalk 2.3.3+ for firmware analysis and extraction, jefferson 0.4+ for JFFS2 filesystem extraction, sasquatch 1.0+ for SquashFS extraction with non-standard compression, firmware-mod-kit for additional manipulation, and unstuff, unrar, 7zip for archive extraction. System tools include busybox for minimal Unix utilities, netcat-openbsd for network connections and debugging, dnsmasq for lightweight DNS/DHCP, bridge-utils for network bridge configuration, and uml-utilities for user-mode Linux. Python libraries include python-magic 0.4+ for file type identification and configparser for configuration file parsing. PostgreSQL 12--15 stores metadata with psycopg2 2.9+ as PostgreSQL adapter for Python.

\subsection{Network Scanner Software}

Python core scanning libraries include scapy 2.4.5+ for packet manipulation and network scanning, python-nmap 0.7+ as Python wrapper for Nmap, and impacket 0.10+ for network protocol implementations. Network utilities include netifaces 0.11+ for network interface enumeration, ipaddress built-in for IP address manipulation, and netaddr 0.8+ for advanced IP handling. Device identification uses mac-vendor-lookup 0.1+ for MAC to vendor mapping and requests 2.28+ as HTTP client for API calls. Parallelization employs concurrent.futures built-in for thread/process pools and asyncio built-in for asynchronous I/O. Data processing uses pandas 1.4+ for data manipulation and numpy 1.22+ for numerical computing. System tools include optional nmap 7.80+, arp-scan 1.9+ as alternative ARP scanner, and masscan 1.3+ as optional high-speed port scanner. MongoDB 5.0--7.0 stores flexible document data with pymongo 4.0+ as MongoDB driver for Python.

\subsection{Malware Classifier Software}

Primary deep learning framework is TensorFlow 2.10--2.13 with Keras API or alternatively PyTorch 1.13--2.1. Data science libraries include numpy 1.23+ for numerical arrays, pandas 1.5+ for data manipulation, scikit-learn 1.2+ for preprocessing and metrics, and scipy 1.10+ for scientific computing. Visualization uses matplotlib 3.6+ for plotting, seaborn 0.12+ for statistical visualization, and plotly 5.13+ for interactive visualizations. Optional GPU acceleration requires CUDA Toolkit 11.8 or 12.0, cuDNN 8.6 or 8.7, and TensorRT 8.5+ for optimized inference. Data handling uses h5py 3.8+ for HDF5 file format, pickle built-in for serialization, and joblib 1.2+ for efficient serialization. Model management optionally uses mlflow 2.1+ for experiment tracking and tensorboard 2.11+ for training visualization. Traffic capture uses pyshark 0.6+ as Python wrapper for tshark/WiShark, pcapy 0.11+ as interface to libpcap, and dpkt 1.9+ for packet creation and parsing.

\subsection{System Integration Software}

Web framework uses Flask 2.2+ or FastAPI 0.95+ for REST API implementation with flask-cors or fastapi-cors for Cross-Origin Resource Sharing and flask-jwt-extended or python-jose for JWT authentication. WSGI server uses gunicorn 20.1+ or uWSGI 2.0+ for production-grade serving. Web server uses nginx 1.22+ or Apache 2.4+ for reverse proxy and load balancing. Optional frontend uses Node.js 18 LTS, React 18+ or Vue.js 3+ framework, D3.js 7+ or Vis.js 9+ for visualizations, and Axios or Fetch API as HTTP client. Data storage uses Redis 7.0+ for caching and queuing with redis-py 4.5+ client, MinIO for S3-compatible object storage, or cloud alternatives AWS S3, Google Cloud Storage, Azure Blob Storage. Optional messaging uses RabbitMQ 3.11+ or Apache Kafka 3.4+ with celery 5.2+ for distributed task queuing. API documentation uses Swagger/OpenAPI 3.0 specification with Redoc or Swagger UI for interactive documentation.

\section{Life Cycle Used}

\subsection{Incremental Software Development Model}

The incremental model divides the project into multiple iterations delivering functional capability subsets. Each increment builds upon previous iterations adding features while refining existing functionality based on testing feedback. This approach aligns with our three-subsystem structure: firmware emulation, network scanning, and malware classification. Early functionality delivery provides usable capabilities enabling stakeholder evaluation and feedback before complete system delivery. Risk mitigation identifies technical challenges early by implementing core functionality first. Flexibility allows requirements evolution between increments based on feedback and lessons learned. Parallel development enables team members working on separate increments concurrently after establishing architectural foundations. The model provides iterative enhancement, stakeholder engagement, and systematic development suitable for our modular architecture.

\subsection{Machine Learning Development Lifecycle}

For malware classification, we follow specialized Machine Learning Development Lifecycle addressing unique ML requirements. The MDLC includes problem definition and scoping precisely defining classification goals and metrics, data collection and ingestion acquiring labeled IoT-23 dataset~\cite{stratosphere}, exploratory data analysis understanding distributions and quality issues, data preprocessing and feature engineering transforming raw traffic into ML-ready features, model selection and architecture design choosing CNN approach and defining network structure, model training implementing training loops with proper validation, model evaluation calculating comprehensive performance metrics, model optimization and tuning improving performance through hyperparameter adjustment, model deployment exporting and serving models via API, and model monitoring and maintenance tracking performance and planning retraining. This structured approach ensures data quality emphasis, iterative refinement, deployment readiness, and reproducibility essential for effective ML development.

\subsection{Project Increments Schedule}

Increment 1 (Weeks 1--8) establishes firmware emulation foundation including development environment setup, firmware extraction implementation, basic QEMU emulation, initial boot arbitration, PostgreSQL database schema, and achieving basic emulation for simple images. Increment 2 (Weeks 6--11) implements network scanner including ARP-based discovery, TCP port scanner with multi-threading, MAC vendor lookup integration, MongoDB schema, command-line interface, and result visualization. Increment 3 (Weeks 9--16) develops deep learning classifier including IoT-23 dataset acquisition and preprocessing, CNN architecture design, training pipeline implementation, initial model training achieving $>$95\% accuracy, inference pipeline development, and model serving API creation. Increment 4 (Weeks 14--20) achieves system integration including unified data model design, RESTful API implementation for all modules, web dashboard development, workflow orchestration, alert generation system, and comprehensive reporting functionality. Increment 5 (Weeks 18--24) focuses on performance optimization including firmware emulation optimization, network scanning performance improvements, model inference speed optimization, Docker containerization, and comprehensive documentation creation. Increment 6 (Weeks 22--28) conducts testing and validation including unit testing, integration testing, performance benchmarking, security testing, and real-world validation with bug fixes. Increment 7 (Weeks 26--30) completes final documentation and presentation including complete project report, presentation materials, demonstration scenarios, packaged deliverables, and final quality assurance.

\section{Software Cost Estimation}

\subsection{COCOMO Model Application}

We employ Constructive Cost Model (COCOMO) for algorithmic cost estimation. COCOMO relates development effort to code size through empirical equations from analysis of hundreds of projects. Basic COCOMO uses equations: Effort (E) = a $\times$ (KLOC)$^b$ person-months, Development Time (D) = c $\times$ (E)$^d$ months, and Personnel (P) = E / D. Our project classification is Semi-Detached due to medium complexity, mixed team experience, some innovative requirements, security-sensitive but not life-critical nature, and moderate technical constraints. For Semi-Detached projects, coefficients are a = 3.0, b = 1.12, c = 2.5, d = 0.35.

\subsection{Code Size and Cost Calculation}

Estimated code size totals 25.1 KLOC including firmware emulation module (4,500 LOC), network scanner module (3,200 LOC), malware classifier module (4,400 LOC), system integration (4,200 LOC), web dashboard (5,000 LOC), and testing and documentation (3,800 LOC). Cost calculation yields Effort E = 3.0 $\times$ (25.1)$^{1.12}$ = 106.26 person-months, Development Time D = 2.5 $\times$ (106.26)$^{0.35}$ = 12.7 months, and Personnel P = 106.26 / 12.7 = 8.37 people. For our 4-person team, adjusted development time is 106.26 / 4 = 26.6 person-months or approximately 6.65 months per person, though realistic project duration is 10--12 months accounting for sequential dependencies, learning curves, integration overhead, and academic commitments.

In academic context, software development cost is \rupee 0 as student labor is not salaried, making total project cost equal to hardware cost only at \rupee 174,700. For industry context assuming \rupee 55,000/month average salary, total development cost is 106.26 $\times$ \rupee 55,000 = \rupee 58,44,300, and total project cost including hardware is \rupee 58,44,300 + \rupee 174,700 = \rupee 60,19,000. Our estimates align with industry benchmarks as security software typically ranges 20--50 KLOC and our 25.1 KLOC falls within this range. The 10--12 month timeline aligns with typical two-semester academic projects.

\section{Hardware Cost Estimation}

Development hardware costs include development workstation with Intel i7--11700K, 32GB RAM, 512GB NVMe SSD, RTX 3060 12GB costing \rupee 120,000; 2TB 7200 RPM HDD for firmware images costing \rupee 4,500; managed Gigabit 8-port switch costing \rupee 3,500; two Raspberry Pi 4 (8GB) units for test IoT network costing \rupee 14,000; ten Cat6 Ethernet cables costing \rupee 1,500; USB-to-Serial FTDI adapter for debugging costing \rupee 800; two surge-protected power strips costing \rupee 2,400; 500GB USB 3.1 SSD for backups costing \rupee 5,500; 27" 1440p IPS display costing \rupee 18,000; and mechanical keyboard plus precision mouse costing \rupee 4,500. Total hardware cost is \rupee 174,700. Component justification includes high-performance workstation essential for running multiple QEMU VMs, training deep learning models efficiently, compiling code, and operating development tools with RTX 3060 GPU providing 10--50x speedup versus CPU. Cost-effective HDD provides sufficient capacity for firmware image collections. Managed switch enables creating isolated test networks, VLAN configuration, and traffic monitoring. Raspberry Pi units simulate real IoT devices. Additional quality peripherals improve productivity during extended development sessions.

\section{Total Product Cost Estimation}

\subsection{Academic and Commercial Context Costs}

For academic context, total project cost equals hardware cost only at \rupee 174,700 (one lakh seventy-four thousand seven hundred rupees only) since software development cost is \rupee 0 for student work. For industry/commercial context, total project cost is \rupee 60,19,000 (sixty lakhs nineteen thousand rupees only) including \rupee 58,44,300 software development plus \rupee 174,700 hardware.

\subsection{Cost-Benefit Analysis}

Tangible annual benefits include prevented security breaches worth \rupee 15--50 lakhs per year assuming 30--50\% breach probability without system at average \rupee 50 lakhs-\rupee 1 crore breach cost, saved labor costs worth \rupee 2.5--5 lakhs per year from 40--80 hours monthly time savings at \rupee 50,000--100,000 monthly analyst salary, automated vulnerability discovery providing 10--100x cheaper pre-deployment identification versus post-deployment fixes, and avoided regulatory fines worth \rupee 2--20 lakhs per year with 20--40\% probability reduction. Total annual tangible benefits conservatively estimate \rupee 20--80 lakhs.

ROI calculation for Year 1 academic context with \rupee 20 lakhs benefits and \rupee 1.75 lakhs costs yields ROI = ((\rupee 20,00,000 - \rupee 1,75,000) / \rupee 1,75,000) $\times$ 100 = 1043\%. Commercial context Year 1 with \rupee 20 lakhs benefits and \rupee 60 lakhs costs yields ROI = -67\% (negative due to development costs), but Year 2 with \rupee 20 lakhs benefits and \rupee 0.5 lakhs maintenance yields ROI = 3900\%. Break-even occurs approximately at 3 years with conservative estimates, earlier with realistic \rupee 40--80 lakhs annual benefits.

\subsection{Comparison to Commercial Alternatives}

Commercial IoT security platforms cost \rupee 5--20 lakhs per year in enterprise licenses, \rupee 2--10 lakhs for professional services implementation, and \rupee 0.75--4 lakhs per year for annual support (15--20\% of license), totaling \rupee 18--72 lakhs over 3 years. Our system 3-year cost is \rupee 1.75 lakhs academic or \rupee 61.5 lakhs commercial versus commercial alternatives, providing cost savings of \rupee 16.25--70.25 lakhs in academic context. Additional advantages include unlimited customization with full source code access, no vendor lock-in maintaining control, complete methodology transparency, community support enabling contributions, and intellectual property ownership.

\section{Project Scheduling using Gantt Chart}

\subsection{Phase Timeline Overview}

Phase 1 Planning and Setup (Weeks 1--3) includes literature review, requirements analysis, environment setup, hardware procurement, team role assignment, and project plan finalization. Phase 2 Firmware Emulation (Weeks 3--10) implements firmware extraction, QEMU emulation setup, arbitration techniques, PostgreSQL integration, and testing. Phase 3 Network Scanner (Weeks 6--13) develops ARP scanner, TCP port scanner, vendor identification, multi-threading optimization, MongoDB integration, and validation. Phase 4 Malware Classifier (Weeks 9--18) handles dataset acquisition, preprocessing pipeline, CNN architecture design, model training and validation, inference pipeline, model serving API, and evaluation. Phase 5 System Integration (Weeks 14--22) creates REST API design, database schema integration, web dashboard development, workflow orchestration, alert generation, report generation, and integration testing. Phase 6 Testing and Validation (Weeks 18--26) includes unit test development, integration testing, performance benchmarking, security testing, bug fixes, and real-world validation. Phase 7 Documentation and Deployment (Weeks 22--28) produces user documentation, developer documentation, Docker containerization, deployment guide, and tutorial creation. Phase 8 Final Report and Presentation (Weeks 26--30) completes project report writing, presentation preparation, demonstration setup, final review and corrections, and final submission.

\subsection{Critical Path and Milestones}

Critical path flows Phase 1 $\rightarrow$ Phase 2 $\rightarrow$ Phase 4 $\rightarrow$ Phase 5 $\rightarrow$ Phase 6 $\rightarrow$ Phase 8 with 30-week duration. Phase 2 firmware emulation must complete before full integration. Phase 4 malware classifier has longest duration and cannot be significantly shortened. Phase 5 integration depends on all three core modules. Phase 6 testing must complete before finalization. Phase 8 report depends on all previous phases. Any critical path delays directly impact completion date. Key milestones include M1 (Week 5) firmware extraction working for 10+ test images, M2 (Week 8) basic emulation successful, M3 (Week 10) arbitration achieving $>$70\% success, M4 (Week 8) ARP scanner discovering all test devices, M5 (Week 11) TCP scanner identifying ports correctly, M6 (Week 13) Class C scan within 5 minutes, M7 (Week 12) dataset preprocessed and ready, M8 (Week 16) model achieving $>$90\% validation accuracy, M9 (Week 18) inference API processing 100+ samples/minute, M10 (Week 16) APIs for all modules functional, M11 (Week 20) dashboard displaying integrated data, M12 (Week 22) end-to-end workflow executing, M13 (Week 21) unit tests passing for all modules, M14 (Week 24) performance targets achieved, M15 (Week 26) no critical bugs remaining, M16 (Week 25) Docker deployment successful, M17 (Week 28) documentation complete, M18 (Week 29) report draft complete, and M19 (Week 30) final submission and presentation.

\subsection{Risk Management Strategy}

Technical risks include low firmware emulation success rate with medium probability and high impact, mitigated by allocating buffer time for additional arbitration development with contingency to reduce firmware variety if success remains below 60\%. Insufficient training data quality has low probability and high impact, mitigated by early dataset acquisition and exploring multiple sources with contingency using transfer learning and data augmentation. Integration complexity has medium probability and medium impact, mitigated by designing clear module interfaces early and incremental integration testing with contingency simplifying integration by focusing on core functionality. Schedule risks include module development delays with medium probability and medium impact, mitigated by parallel development and front-loading critical activities with contingency reallocating resources. Hardware procurement delays have low probability and low impact, mitigated by immediate ordering upon approval with contingency using cloud resources temporarily. Resource risks include team member unavailability with medium probability and medium impact, mitigated by cross-training and comprehensive documentation with contingency redistributing tasks. Contingency buffer incorporates 2--3 weeks distributed as Phase 2 buffer (1 week at Week 10), Phase 4 buffer (1 week at Week 17), Phase 6 buffer (1 week at Week 25), and final buffer (1 week at Week 29) absorbing minor delays without impacting completion.